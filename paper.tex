\documentclass[10pt]{article}

% amsmath package, useful for mathematical formulas
\usepackage{amsmath}
% amssymb package, useful for mathematical symbols
\usepackage{amssymb}

% graphicx package, useful for including eps and pdf graphics
% include graphics with the command \includegraphics
\usepackage{graphicx}

% cite package, to clean up citations in the main text. Do not remove.
\usepackage{cite}

\usepackage{color} 

% Use doublespacing - comment out for single spacing
\usepackage{setspace} 
\doublespacing


% Parse trees
\usepackage{qtree}

% Use the PLoS provided bibtex style
% \bibliographystyle{PLoS2009}
\bibliographystyle{unsrt}

% Remove brackets from numbering in List of References
\makeatletter
\renewcommand{\@biblabel}[1]{\quad#1.}
\makeatother


% Leave date blank
\date{}

\pagestyle{myheadings}
%% ** EDIT HERE **
%% Please insert a running head of 30 characters or less.  
%% Include it twice, once between each set of braces
\newcommand\titlestring{Stochastic tree-adjoining grammars for modeling retrotransposons}
\newcommand\authorstring{
Lawrence Uricchio, Ian Holmes
}

\markboth{\titlestring}{\titlestring}


%% ** EDIT HERE **
%% PLEASE INCLUDE ALL MACROS BELOW

\usepackage{setspace}
\doublespacing



\usepackage{array}


% Labels & references for sections, figures and tables
% Comment out \secref and \seclabel for PLoS -- they don't have numbered section references.
\newcommand{\secref}[1]{Section~\ref{sec:#1}}
\newcommand{\seclabel}[1]{\label{sec:#1}}
\newcommand{\secname}[1]{``#1''}  % PLoS-style section names

% "Text S1", "Text S2", etc.
\newcommand{\supptext}[1]{Text S#1}

% "Dataset S1", "Dataset S2", etc.
\newcommand{\dataset}[1]{Dataset S#1}

% Appendix
\newcommand{\appref}[1]{Appendix~\ref{app:#1}}
\newcommand{\applabel}[1]{\label{app:#1}}

% Figure
\newcommand{\figref}[1]{Figure~\ref{fig:#1}}
\newcommand{\figlabel}[1]{\label{fig:#1}}

% Table
\newcommand{\tabnum}[1]{\ref{tab:#1}}
\newcommand{\tabref}[1]{Table~\tabnum{#1}}
\newcommand{\tablabel}[1]{\label{tab:#1}}

% Equation
\newcommand{\eqnref}[1]{Equation~\ref{eqn:#1}}
\newcommand{\eqnlabel}[1]{\label{eqn:#1}}


% need cite, check me, and other notes to self
\newcommand\needcite{{\bf [CITE]}}
\newcommand\checkme{{\bf [CHECK]}}



%% END MACROS SECTION

\begin{document}

% Title must be 150 words or less
\begin{flushleft}
  {\Large
    \textbf{\titlestring}
  }
\\
\authorstring
\end{flushleft}


% Please keep the abstract between 250 and 300 words
%\newpage
\section*{Abstract}
TAGs and parsers for biological repeats.

% Table of contents
\tableofcontents

% Please keep the Author Summary between 150 and 200 words
% Use first person. PLoS ONE authors please skip this step. 
% Author Summary not valid for PLoS ONE submissions.   
%\newpage
%\section{Author Summary}


\section{Introduction}

Transposable elements (TEs), or {\em transposons}, are of great interest in molecular evolution \cite{Feschotte2007}, and an important aspect of genome annotation.
There are several specializations in the overall task of transposon annotation:
PILER \cite{EdgarMyers2005} specializes in {\em de novo} transposon discovery,
while REPCLASS specializes in classification of found transposons \cite{FeschotteKeswaniEtAl2009}.

Many such programs classify TEs by their general structural features, particularly their terminal repeats:
LTRs (Long Terminal Repeats) and TIRs (Terminal Inverted Repeats).

It is useful to build databases and profiles of known transposon families, for the purpose of classifying new ones.
To date, the most comprehensive database of known transposons is REPBASE \cite{KapitonovJurka2008},
whose profiles rely only on primary sequence homology models;
that is, they do not make explicit use of terminal repeat structure.

A promising approach, that combines profile Hidden Markov Models (HMMs) of primary sequence homology (at the level of TE protein domains)
with fast algorithms for detecting LTRs,
is taken by LTRdigest \cite{pmid19786494}.
The purpose of this paper is to represent the hybrid modeling approach of LTRdigest using formal grammars.

\section{Definitions}

\subsection{Tree-Adjoining Grammars}

We define a minimal normal form of Tree-Adjoining Grammars (TAGs)
suited to biological sequence analysis,
as opposed to the linguistic representation elsewhere \cite{JoshiSchabes97}.
TAGs have previously been used in bioinformatics
to model pseudoknots and other RNA structures \cite{MatsuiEtAl2005,ChiangJoshiSearls2006}
and to model local duplications (Hickey and Blanchette, pers. comm.).

\newcommand\grammar{{\cal G}}
\newcommand\nodelabels{{\cal N}}
\newcommand\terminals{{\cal T}}
\newcommand\startsymbol{S}
\newcommand\rules{{\cal R}}
\newcommand\weight{{\cal W}}

A TAG is a tuple $\grammar=(\nodelabels,\terminals,\startsymbol,\rules,\weight)$ where
$\nodelabels$ is a finite set of {\em node labels},
$\terminals$ is a finite set of {\em terminals} (disjoint from $\nodelabels$),
$\startsymbol \in \nodelabels$ is a distinguished {\em start label},
$\rules$ is a finite set of {\em transformation rules}
and $\weight:\rules \to [0,\infty)$ is a {\em rule weight function}.

\newcommand\outseq{Z}
\newcommand\outsubseq[2]{\outseq[#1 \ldots #2]}

The process of generating an output sequence $\outseq \in \terminals^\ast$ using $\grammar$
is referred to as a {\em derivation} of $\outseq$.
The derivation consists of repeated local application of transformation rules to {\em intermediate trees}.
We can commence a derivation from any {\em initial tree}, but ultimately we will be interested in derivations that commence with the following initial tree

\newcommand\lineartree[3]{\Tree[ .$#1$ [ .$#2$ [ .$#3$ ] ] ]}
\newcommand\inittree[1]{\lineartree{\epsilon}{#1}{\epsilon}}

\inittree{\startsymbol}

\newcommand\rulesubset[2]{\rules_{#1}(#2)}


\newcommand\abtree[1]{\lineartree{\alpha}{#1}{\beta}}
\newcommand\lhs{\abtree{A}}

%\newcommand\bigrhsA{\Tree[ .$\alpha$ [ .$B$ [ [ [ .$C$ $\epsilon$ ] ] [ [ .$\beta$ ] ] ] ] ]}
%\newcommand\bigrhsB{\Tree[ .$\alpha$ [ .$B$ [ [ [ .$\beta$ ] ] [ [ .$C$ $\epsilon$ ] ] ] ] ]}
%\newcommand\bigrhsC{\Tree[ .$\alpha$ [ [ [ .$C$ $\epsilon$ ] ] [ [ .$B$ $\beta$ ] ] ] ]}
%\newcommand\bigrhsD{\Tree[ .$\alpha$ [ [ [ .$B$ $\beta$ ] ] [ [ .$C$ $\epsilon$ ] ] ] ]}
%\newcommand\bigrhsE{\Tree[ .$\alpha$ [ .$B$ [ .$C$ $\beta$ ] ] ]}
%\newcommand\bigrhsF{\Tree[ .$\alpha$ [ $u$ [ .$B$ [ $v$ [ $\beta$ ] $x$ ] ] $y$ ] ]}

\newcommand\tinyrhsA{\Tree[ .$\alpha$ [ .$C$ [ .$U$ $\epsilon$ ] [ .$\beta$ ] ] ]}
\newcommand\tinyrhsB{\Tree[ .$\alpha$ [ .$C$ [ .$\beta$ ] [ .$Y$ $\epsilon$ ] ] ]}
\newcommand\tinyrhsC{\Tree[ .$\alpha$ [ .$V$ $\epsilon$ ] [ .$C$ $\beta$ ] ]}
\newcommand\tinyrhsD{\Tree[ .$\alpha$ [ .$C$ $\beta$ ] [ .$X$ $\epsilon$ ] ]}
\newcommand\tinyrhsE{\Tree[ .$\alpha$ [ .$B$ [ .$C$ $\beta$ ] ] ]}
%\newcommand\tinyrhsF{\Tree[ .$\alpha$ $u$ [ .$C$ $v$ $\beta$ $x$ ] $y$ ]}
\newcommand\tinyrhsF{\abtree{C}}
 
%\newcommand\tinynewickA{((\beta)A)\alpha \to ((U,\beta)C)\alpha}
%\newcommand\tinynewickB{((\beta)A)\alpha \to ((\beta,Y)C)\alpha}
%\newcommand\tinynewickC{((\beta)A)\alpha \to (V,((\beta)C))\alpha}
%\newcommand\tinynewickD{((\beta)A)\alpha \to (((\beta)C),X)\alpha}
%\newcommand\tinynewickE{((\beta)A)\alpha \to (((\beta)C)B)\alpha}
%\newcommand\tinynewickF{((\beta)A)\alpha \to (u,((v,\beta,x)C),y)\alpha}

\newcommand\rhs[6]{\Tree[ .$\alpha$ [ .$#1$ [ .$#3$ $\epsilon$ ] [ .$#2$ [ .$#4$ $\epsilon$ ] $\beta$ [ .$#5$ $\epsilon$ ] ] [ .$#6$ $\epsilon$ ] ] ]}
\newcommand\rhsnob[5]{\Tree[ .$\alpha$ $#2$ [ .$#1$ $#3$ $\beta$ $#4$ ] $#5$ ]}
\newcommand\rhsnoepsilon[6]{\Tree[ .$\alpha$ [ .$#1$ $#3$ [ .$#2$ $#4$ $\beta$ $#5$ ] $#6$ ] ]}
\newcommand\rhsnouvxy[2]{\Tree[ .$\alpha$ [ .$#1$ [ .$#2$ $\beta$ ] ] ]}

\newcommand\rhsGeneric{\rhs{B}{C}{U}{V}{X}{Y}}

\newcommand\rhsA{\Tree[ .$\alpha$ [ .$U$ $\epsilon$ ] [ .$C$ $v$ $\beta$ $x$ ] $y$ ]}
\newcommand\rhsB{\Tree[ .$\alpha$ $u$ [ .$C$ $v$ $\beta$ $x$ ] [ .$Y$ $\epsilon$ ] ]}
\newcommand\rhsC{\Tree[ .$\alpha$ $u$ [ .$C$ [ .$V$ $\epsilon$ ] $\beta$ $x$ ] $y$ ]}
\newcommand\rhsD{\Tree[ .$\alpha$ $u$ [ .$C$ $v$ $\beta$ [ .$X$ $\epsilon$ ] ] $y$ ]}
\newcommand\rhsE{\rhsnoepsilon{B}{C}{u}{v}{x}{y}}
\newcommand\rhsF{\rhsnob{C}{u}{v}{x}{y}}

\newcommand\newickA{((\beta)A)\alpha \to (U,((v,\beta,x)C),y)\alpha}
\newcommand\newickB{((\beta)A)\alpha \to (u,((v,\beta,x)C),Y)\alpha}
\newcommand\newickC{((\beta)A)\alpha \to (u,((V,\beta,x)C),y)\alpha}
\newcommand\newickD{((\beta)A)\alpha \to (u,((v,\beta,X)C),y)\alpha}
\newcommand\newickE{((\beta)A)\alpha \to ((u,((v,\beta,x)C),y)B)\alpha}
\newcommand\newickF{((\beta)A)\alpha \to (u,((v,\beta,x)C),y)\alpha}

\newcommand\longnewickA{((\beta)A)\alpha \to ((\epsilon)U,((v,\beta,x)C),y)\alpha}

Each ``intermediate tree'' is, formally, an ordered tree whose nodes are labeled from
$(\nodelabels \cup \terminals^\ast)$.
The transformation rules can take the various forms shown in \tabref{RuleTypes}.
All the rules may be recognized as special cases of the general form

\begin{tabular}{m{1in}m{.2in}m{1in}}
\lhs & $\to$ & \rhsGeneric
\end{tabular}

where $U,V,X,Y \in (\nodelabels \cup \terminals^\ast)$
and $B,C \in (\nodelabels \cup \{\epsilon\}^\ast)$.
The tree is ordered left-to-right.

The derivation stops when no further transformations can be applied.
The trees generated by this process have the property that every leaf node is labeled with a terminal sequence,
while every internal node is labeled either with $\epsilon$, or with a member of $\nodelabels$
which never appears on the left-hand side of a rule in $\rules$
(and to which no transformations can therefore be applied).

To obtain the final output sequence, we read off the terminal sequences (at the leaves) in a depth-first traversal of the ordered tree
(i.e. from just left of the root, moving anticlockwise around the tree, to just right of the root).
The depth-first order of leaves in the general tree shown above is $(U,V,\beta,X,Y)$.

\newcommand\seqweight[2]{\weight \left[ {#1} \Rightarrow {#2} \right]}

The {\em weight} of a derivation is the product of the weights of all rules used in the derivation.
The weight of a given output sequence $\outseq$ is the sum of the weights of all possible derivations of $\outseq$.
Let $\seqweight{\alpha}{\outseq}$ denote the weight of output sequence $\outseq$,
starting from initial tree $\alpha$.

The final column of \tabref{RuleTypes} shows a shorthand representation of each rule in Newick format,
probably the most widely-understood bioinformatics format for representing tree structures.
The initial tree, in this representation, is $((\epsilon)S)\epsilon$.
In the table, we have omitted the placeholder $\epsilon$'s at leaf nodes,
so that (for example) the rule
\[
\newickA
\]
should strictly be read as
\[
\longnewickA
\]

Let $\rulesubset{n}{A}$ denote the subset of rules of type $n$ (according to \tabref{RuleTypes})
where the left-hand side is $((\beta)A)\alpha$ for a given $A \in \nodelabels$.

Note the special case of a type-6 rule where all the terminal strings are empty,
$((\beta)A)\alpha \to ((\beta)C)\alpha$.
Such a rule is referred to as a {\em transition} and may be written more compactly as $A \to C$.

\begin{table}
\tiny
\begin{tabular}{m{.2in}m{.2in}m{.2in}m{1in}cm{1.2in}}
\centerline{Type} & \centerline{From} & & \centerline{To} & Newick representation & When $uvxy=\epsilon$:
\\ \hline
(1) &
\lhs & $\to$ & \rhsA & $\newickA$ & \tinyrhsA
\\ \hline
(2) &
\lhs & $\to$ & \rhsB & $\newickB$ & \tinyrhsB
\\ \hline
(3) &
\lhs & $\to$ & \rhsC & $\newickC$ & \tinyrhsC
\\ \hline
(4) &
\lhs & $\to$ & \rhsD & $\newickD$ & \tinyrhsD
\\ \hline
(5) &
\lhs & $\to$ & \rhsE & $\newickE$ & \tinyrhsE
\\ \hline
(6) &
\lhs & $\to$ & \rhsF & $\newickF$ & \tinyrhsF
\\ \hline
\end{tabular}
\normalsize
\caption{
\tablabel{RuleTypes}
Types of transformation rule (i.e. tree adjunction rule) used in this paper.
Here $\alpha,\beta$ represent any subtree;
$A \in \nodelabels$ is the source node label;
$B,C,U,V,X,Y \in (\nodelabels \cup \{\epsilon\})$ are the destination node labels;
$\epsilon$ is the empty string;
and
$u,v,x,y \in \terminals^\ast$ are (possibly empty) terminal strings.
The final column shows the destination tree when all the terminal strings $u,v,x,y$ are empty.
}
\end{table}

\subsection{A parsing algorithm}

We can define a general parsing algorithm for TAGs
that is the equivalent of the CYK (Cocke-Younger-Kasami) algorithm for SCFGs.
The CYK algorithm is closely related to the Inside algorithm,
which computes the weight (probability) of a given output sequence.
Here, we present the Inside version of the TAG algorithm;
to obtain the CYK version, simply replace all summation operators ($\Sigma$)
with max operators.

For the given output sequence $\outseq \in \terminals^\ast$, let $\outsubseq{i}{j+1}$ denote the substring from $i$ through $j$ inclusive, for $1 \leq i \leq j \leq |\outseq|$.
Let $\outsubseq{i}{i} = \epsilon$.

\newcommand\match{\Delta}
\newcommand\fmatch{\stackrel{\rightarrow}{\match}}
\newcommand\rmatch{\stackrel{\leftarrow}{\match}}
\newcommand\iumatch{\match_{iu}}
\newcommand\jvmatch{\match_{jv}}
\newcommand\kxmatch{\match_{kx}}
\newcommand\lymatch{\match_{ly}}

Define some indicator functions to match output substrings to rules
\begin{eqnarray*}
\match(i,j,x) & = & \delta \left( \outsubseq{i}{j}\ =\ x \right) \\
\fmatch(i,x) & = & \match(i,i+|x|,x) \\
\rmatch(j,y) & = & \match(j-|y|,j,y) \\
\iumatch & = & \fmatch(i,u) \\
\jvmatch & = & \rmatch(j,v) \\
\kxmatch & = & \fmatch(k,x) \\
\lymatch & = & \rmatch(l,y)
\end{eqnarray*}

\subsubsection{The dynamic programming matrix}

\newcommand\m{M}
\newcommand\mtip{\m'}

Introducing the placeholder $\gamma$ as an additional terminal, define
\begin{eqnarray*}
\m(i,j,k,l,A) & = & \seqweight{((\gamma)A)\epsilon}{\outsubseq{i}{j} \gamma \outsubseq{k}{l}} \\
\mtip(i,l,A) & = & \seqweight{((\epsilon)A)\epsilon}{\outsubseq{i}{l}}
\end{eqnarray*}
where $1 \leq i \leq j \leq k \leq l \leq |\outseq|$.

Thus $\m(i,j,k,l,A)$ is the probability that the initial tree $((\gamma)A)\epsilon$ will generate 
$\outsubseq{i}{j}$ to the left of $\gamma$ and $\outsubseq{k}{l}$ to the right of $\gamma$,
whereas $\mtip(i,l,A)$ is the probability that the initial tree $((\epsilon)A)\epsilon$ will generate 
$\outsubseq{i}{l}$.
Note that

\[
\mtip(i,l,A) = \sum_{k=i}^l \m(i,k,k,l,A)
\]

Note also the following boundary conditions:
\begin{eqnarray*}
\m(i,i,k,k,\epsilon) & = & 1 \\
\mtip(i,i,\epsilon) & = & 1
\end{eqnarray*}

The {\em inside sequence} refers to the sequences $\outsubseq{i}{j}$ and $\outsubseq{k}{l}$ (for $\m$),
or the sequence $\outsubseq{i}{l}$ (for $\mtip$).

\subsubsection{The dynamic programming recursion}

The DP recursion relation is as follows (with $B,C,U,V,X,Y,u,v,x,y$ defined as in \tabref{RuleTypes})
\begin{eqnarray*}
\lefteqn{\m(i,j,k,l,A) =} \\
& &
\sum_{\rho \in \rulesubset{1}{A}} \sum_{m=i}^j W(\rho) \m(m,j-|v|,k+|x|,l-|y|,C) \mtip(i,m,U) \jvmatch \kxmatch \lymatch \\
& & +
\sum_{\rho \in \rulesubset{2}{A}} \sum_{n=k}^l W(\rho) \m(i+|u|,j-|v|,k+|x|,n,C) \mtip(n,l,Y) \iumatch \jvmatch \kxmatch \\
& & +
\sum_{\rho \in \rulesubset{3}{A}} \sum_{m=i}^j W(\rho) \m(i+|u|,m,k+|x|,l-|y|,C) \mtip(m,j,V) \iumatch \kxmatch \lymatch \\
& & +
\sum_{\rho \in \rulesubset{4}{A}} \sum_{n=k}^l W(\rho) \m(i+|u|,j-|v|,n,l-|y|,C) \mtip(k,n,X) \iumatch \jvmatch \lymatch \\
& & +
\sum_{\rho \in \rulesubset{5}{A}} \sum_{m=i}^j \sum_{n=k}^l W(\rho) \m(i+|u|,m,n,l-|y|,B) \m(m,j-|v|,k+|x|,n,C) \iumatch \jvmatch \kxmatch \lymatch \\
& & +
\sum_{\rho \in \rulesubset{6}{A}} W(\rho) \m(i+|u|,j-|v|,k+|x|,l-|y|,C)
 \iumatch \jvmatch \kxmatch \lymatch
\end{eqnarray*}

Note that for $\m$ to be exactly computable, we require that there are no {\em null cycles} in the grammar.
A null cycle is a series of transformations that, when applied consecutively to a given tree $\alpha$, yield the original tree $\alpha$ again,
or one that is trivially related to it (e.g. a tree that is identical to $\alpha$ after $\epsilon$-labeled nodes of degree $<3$ have been removed).
Null cycles frequently arise via consecutive transitions of the form $A \to B$ followed by $B \to A$,
but there are other possibilities too (for example, a type-1 bifurcation rule $((\beta)A)\alpha \to ((U,\beta)C)\alpha$
followed by two transitions $U \to \epsilon$ and $C \to A$).

A {\em Lexicalized TAG} (LTAG) has the property that one of $u,v,x,y$ is always a nonempty terminal string,
guaranteeing that it contains no null cycles,
and ensuring that every rule explicitly matches some output characters.
LTAGs are popular in linguistics, though the constraint is possibly too stringent to be helpful for bioinformatics grammars.

\subsubsection{Fill order}

The absence of null cycles implies that we can perform a {\em topological sort} (topo-sort) of $\nodelabels$ based on the transition graph,
yielding the order in which node labels must be visited in the Inside algorithm.

A suitable (but non-unique) Inside fill order is as follows:
\begin{itemize}
 \item For $L_1 = 0$ to $|Z|$ (increasing), \quad $i = 0$ to $|Z|-L_1$ (increasing):
 \begin{itemize}
  \item Let $l = i + L_1$
  \item For $L_2 = L_1$ to $0$ (decreasing), \quad $j = i$ to $i + L_1 - L_2$ (increasing):
  \begin{itemize}
   \item Let $k = j + L_2$
   \item For $A \in \nodelabels$ (topo-sorted, transition destinations before sources):
   \begin{itemize}
    \item Compute $\m(i,j,k,l,A)$ and store
   \end{itemize}
  \end{itemize}
  \item For $A \in \nodelabels$ (topo-sorted, transition destinations before sources):
  \begin{itemize}
   \item Compute $\mtip(i,l,A)$ and store
  \end{itemize}
 \end{itemize}
\end{itemize}


\subsubsection{Length distributions}

To model genomic features, it is extremely useful to augment the TAG framework with length distributions;
that is, to allow the rule weight $\weight(\rho)$ to depend on distances
such as $m-i$, $j-m$, $n-k$, $l-n$, $n-m$, $j-i$, $k-j$, $l-k$, $l-i$ and so on.

Note that the TAG framework implicitly allows some length distributions to be constructed, even without such augmentation;
for example, the ``waiting time'' in a particular state is geometrically-distributed, and by arranging a series of such states,
one can obtain other distributions, e.g. a negative binomial distribution.
One can also obtain any distribution over a random variable $x \leq N$ by using $N$ states,
or approximate any distribution to some degree of precision with a finite number of states.
However, it is often much more convenient and efficient simply to allow $\weight$ to sometimes depend directly on the inside sequence length.

\section{A simple retrotransposon grammar}
\seclabel{RetroGrammar}

We are particularly interested in following class of grammars that describe specific arrangements of DNA-encoded protein domains flanked by LTRs (long terminal repeats).

\subsection{SCFG and LTR components}

The LTRs can be generated by type-6 rules (e.g. with $v=y=\epsilon$) followed either by a transition to the transposon interior,
or (optionally) a type-5 adjunction rule, which may be an easier event on which to impose a hint-requirement constraint.

\subsection{Developing the SCFG sub-grammar for transposon contents}

\begin{itemize}
\item $X$ generates a nucleotide sampled from the background distribution
\item $X_L$ generates $\ell$ background nucleotides, where $\ell \sim L$
\item $F_N$ samples a DNA sequence coding for family $N$ from PFAM \cite{Pfam2008}
\item $I_L$ generates an intron of length $\ell \sim L$ (can be emitted by $F_N$)
\item $T_A$ generates a terminal inverted repeat, then transits to $A$
\end{itemize}
We can also make transitions back to $\startsymbol$ to generate a nested transposon insertion.

The grammar so described has some similarities to LTRdigest \cite{pmid19786494} and TENest \cite{KronmillerWise2008}.


\subsection{Supplying external hints}

The parsing algorithm uses ${\cal O}(|\outseq|^4)$ memory and ${\cal O}(|\outseq|^6)$ time.
The hope is to accelerate it significantly by using externally-supplied ``hints''
as constraints on the locations of various features (especially the LTRs).

The hints file should include
\begin{itemize}
\item A set of tuples $(i,j,k,l)$ indicating that $\outsubseq{i}{j}$ and $\outsubseq{k}{l}$ are (respectively) the 5' and 3' repeat regions of an LTR
\item A set of tuples $(i,j,N)$ indicating that $\outsubseq{i}{j}$ is a match to PFAM family $N$
\end{itemize}

These hints can be generated by fast tools, e.g. suffix-tree based algorithms for finding LTRs \cite{pmid16819780},
or GeneWise for finding DNA sequences that code for PFAM protein domains \cite{BirneyEtAl04}.

A very quick heuristic that might achieve most of the benefits of a more rigorous ``hints'' constraint
would be to divide the genome into windows and only run the grammar on windows which contain $K$ or more of the appropriate hints.

\section{Glossary of mathematical notation}

\noindent
\begin{tabular}{ll}
Symbol & Meaning \\
\hline
$\grammar$ & Grammar \\
$\nodelabels$ & Set of node labels \\
$\terminals$ & Set of terminals \\
$\rules$ & Set of transformation rules \\
$\rulesubset{n}{A}$ & Set of transformation rules of type $n$ (see \tabref{RuleTypes}) whose LHS is $((\beta)A)\alpha$ \\
$\alpha,\beta$ & Arbitrary ordered node-labeled trees \\
$\weight$ & Rule weight function \\
$\seqweight{\alpha}{\outseq}$ & Sum, over derivations of $\outseq$ from $\alpha$, of product over derivation rule weights \\
$\epsilon$ & The empty string \\
$\terminals^\ast$ & Set of strings over $\terminals$, including the empty string \\
$\outseq$ & Output sequence \\
$|\outseq|$ & Length of $\outseq$ \\
$\outsubseq{i}{j+1}$ & Substring of $\outseq$ from $i$ to $j$ inclusive ($i$ starts at 1) \\
$\outsubseq{i}{i}$ & The empty string \\
$\match(i,j,x)$ & Indicates if rule string $x$ matches output string $\outsubseq{i}{j}$ \\
$\fmatch(i,x)$ & Indicates if rule string $x$ matches output string $\outseq$, starting at position $i$ \\
$\rmatch(j,y)$ & Indicates if rule string $y$ matches output string $\outseq$, ending before position $j$ \\
$\iumatch,\jvmatch,\kxmatch,\lymatch$ & Rule string matchers; $\match_{ns}$ matches string $s$ ending/starting at position $n$ \\
$\m(i,j,k,l,A)$ & Inside weight for $\outsubseq{i}{j}$ (left) and $\outsubseq{k}{l}$ (right) rooted at $A$ \\
$\mtip(i,l,A)$ & Inside weight for $\outsubseq{i}{l}$ rooted at $A$ \\
$B,C,U,V,X,Y$ & Labels (or terminal strings) at nodes of the Newick tree $((U,((V,\beta,W)C),X)B)\alpha$ \\
$u,v,x,y$ & Special symbols for $U,V,X,Y$ when they are terminal strings \\
\end{tabular}

% Do NOT remove this, even if you are not including acknowledgments
\newpage
\section{Acknowledgments}

Sean Eddy co-organized an excellent workshop at U.Penn, ``Language Modeling of Biological Data'',
at which IH met Mark Steedman, Bonnie Webber and Aravind Joshi,
and learned from them (and others) the secrets of TAGs, finite-state transducers, and mildly context-sensitive grammars.
David Searls has been a long-time proponent of linguistics applied to bioinformatics.
Dan Klein encouraged us to develop our own variations on grammar frameworks.
Michael Souza introduced us to the pumping lemma and the equivalence of TAGs with various other frameworks.

\section{References}
% The bibtex filename(s)
\bibliography{../latex-inputs/alignment,../latex-inputs/reconstruction,../latex-inputs/duplication,../latex-inputs/genomics,../latex-inputs/ncrna,../latex-inputs/url,../latex-inputs/transposon}

%\clearpage
%\section{Figure Legends}

\end{document}

